{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b37330d-78f2-48df-8b2c-a8c13a81c807",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "Declaration with PyTorch's Dataset heritance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76646a3d-a291-4aea-a313-d6272b73a71c",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": true,
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import glob\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from music21 import instrument as m21instrument\n",
    "from time import sleep\n",
    "\n",
    "def performanceDecode(performance: pd.DataFrame):\n",
    "        '''\n",
    "            Receive a EPMS Performance Block and separe\n",
    "            the data into a Multi Hot Encoding (MHE) representation\n",
    "            of the notes played and a int (vector?) with\n",
    "            the velocity of the notes (range 0-127)\n",
    "        '''\n",
    "        performance = performance.to_numpy()\n",
    "        # print(f'perf Shape: {performance.shape}')\n",
    "        if performance.shape[0] == 0:\n",
    "            return None\n",
    "\n",
    "        mhe = np.zeros(performance.shape).astype(int)\n",
    "        # print(mhe.shape)\n",
    "        velocities = np.zeros(performance.shape).astype(float)\n",
    "\n",
    "        for i, frame in enumerate(performance):\n",
    "            # print(frame)\n",
    "            for j, note_value in enumerate(frame):\n",
    "                if type(note_value) is bool:\n",
    "                    mhe[i][j] = 0\n",
    "                    velocities[i][j] = 0\n",
    "                else:\n",
    "                    mhe[i][j] = 1\n",
    "                    velocities[i][j] = note_value\n",
    "\n",
    "        return [mhe, velocities]\n",
    "\n",
    "\n",
    "class InstrumentDataset(Dataset):\n",
    "    '''\n",
    "        pianoDataset = InstrumentDataset(path, m21.instruments.Piano)\n",
    "        pianoDataLoader = DataLoader(pianoDataset, batch_size=1, shuffle=True)\n",
    "\n",
    "        for song in pianoDataLoader:\n",
    "            pass\n",
    "    '''\n",
    "\n",
    "    def __init__(self, root_dir:str, instrument:str, keyboard_size:int):\n",
    "        self.root_dir = root_dir\n",
    "        self.instrument = instrument\n",
    "        self.keyboard_size = keyboard_size\n",
    "        self.dataset_files = glob.glob(f'{root_dir}**/**.pkl', recursive=True)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset_files)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # retorna um MHE e um VELOCITIES\n",
    "        pkl_file_path = Path(self.dataset_files[idx])\n",
    "        # print(pkl_file_path)\n",
    "        file_data = pd.read_pickle(pkl_file_path)\n",
    "        # print(file_data)\n",
    "        # print(type(self.instrument))\n",
    "        instrument_data = file_data[file_data.INSTRUMENT==self.instrument]\n",
    "        # print(instrument_data)\n",
    "        # print\n",
    "\n",
    "        # print(len(instrument_data))\n",
    "        # if len(instrument_data == 0):\n",
    "        #     return [1]\n",
    "\n",
    "        # print(instrument_data)\n",
    "        performance = instrument_data.iloc[:, (len(instrument_data.columns) - self.keyboard_size):]\n",
    "\n",
    "        result = performanceDecode(performance)\n",
    "\n",
    "        if result is None:\n",
    "            return []\n",
    "\n",
    "        return result\n",
    "\n",
    "class TrainingSamples(Dataset):\n",
    "    '''\n",
    "        training_samples = TrainingSamples(song, 16, 88)\n",
    "\n",
    "        # DL depth = 1\n",
    "        training_dataloader = DataLoader(training_samples, batch_size=1, shuffle=False)\n",
    "\n",
    "        # DL depth = 4\n",
    "        training_dataloader = DataLoader(training_samples, batch_size=4, shuffle=False)\n",
    "\n",
    "        for sample in training_dataloader:\n",
    "            agent.predictor.train()\n",
    "    '''\n",
    "\n",
    "    def __init__(self, samples:np.array, resolution:int):\n",
    "        # recebe um Dataframe\n",
    "        self.samples = samples\n",
    "        # print(f'[TrainingSamples Shape] {self.samples.shape}')\n",
    "        self.resolution = resolution\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples) - self.resolution - 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # retorna um dataframe do tamannho da resolucao\n",
    "        sample_no_shift = np.array(self.samples[idx:idx + self.resolution, :])\n",
    "        sample_shiftted = np.array(self.samples[idx+1:idx + self.resolution+1, :])\n",
    "        # only returning mhe for now\n",
    "        return (torch.from_numpy(sample_no_shift).float(), torch.from_numpy(sample_shiftted).float())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}