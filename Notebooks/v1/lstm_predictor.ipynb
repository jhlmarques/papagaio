{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db916be0-f208-411f-9bbe-b691b4b6148c",
   "metadata": {
    "gradient": {
     "editing": true,
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import pprint\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "class PerformanceLSTM(nn.Module):\n",
    "    def __init__(self,\n",
    "                 # embeddings: nn.Module,\n",
    "                 input_size: int,\n",
    "                 hidden_size: int,\n",
    "                 num_layers: int,\n",
    "                 device:str):\n",
    "        super(PerformanceLSTM, self).__init__()\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # self.embeddings = embeddings\n",
    "#         print(self.embeddings)\n",
    "        self.model = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True).to(self.device)\n",
    "        self.fc = nn.Linear(hidden_size*2, input_size, bias=False).to(self.device) # Fully connected layer\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softplus = nn.Softplus(beta=500, threshold=0)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        # summary(self.model, (1, 16, 88))\n",
    "\n",
    "        print(f'= MODELO = ')\n",
    "        print(f'\\n{self.model}\\n')\n",
    "        print(f'\\n{self.fc}\\n')\n",
    "        print('='*42)\n",
    "        # summary(self.lstm, (88, 88))\n",
    "\n",
    "        # self.lr = 3e-4 # Learning Rate\n",
    "        # self.adam_optimizer = optim.Adam(self.parameters(), lr=lr)\n",
    "        # self.sgd_optimizer = optim.SGD(self.parameters(), lr=lr)\n",
    "        # self.loss_fn = nn.BCELoss() # Binary Cross Entropy\n",
    "\n",
    "\n",
    "    def forward(self, input_seq, hidden, cell):\n",
    "\n",
    "        # print('FORWARD')\n",
    "\n",
    "#         print(input_seq)\n",
    "\n",
    "#         ix_to_word = np.load('Embeddings/ix_to_word.npy', allow_pickle=True)\n",
    "#         word_to_ix = np.load('Embeddings/word_to_ix.npy', allow_pickle=True)\n",
    "#         print(ix_to_word)\n",
    "#         print(word_to_ix)\n",
    "\n",
    "        # (1, 16, 88) -> floats\n",
    "        input_seq = input_seq.to(self.device)\n",
    "\n",
    "#         for batx in input_seq:\n",
    "#             for frame in batx:\n",
    "#                 frame = self.embeddings.weight[word_to_ix[tuple(frame)]]\n",
    "\n",
    "        # 64 = EMBEDDING_DIM\n",
    "        # (1, 16, 64) -> floats\n",
    "\n",
    "        # print(input_seq)\n",
    "        # print('Input shape: ', len(input_seq))\n",
    "\n",
    "        # print(input_seq.shape)\n",
    "\n",
    "        # Passing in the input and hidden state into the model and obtaining outputs\n",
    "        output_seq, (hidden, cell) = self.model(input_seq, (hidden, cell))\n",
    "        # print('Output shape: ', output_seq.shape, output_seq)\n",
    "\n",
    "        # expanded_output_seq -> (1, 16, 176)\n",
    "\n",
    "        # Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        output_seq = output_seq.contiguous().view(-1, self.hidden_size*2)\n",
    "        # print('Output shape B: ',output_seq.shape)\n",
    "        output_seq = output_seq.squeeze(-1)\n",
    "        # print('Output shape C: ',output_seq.shape, output_seq)\n",
    "\n",
    "        # expanded_output_seq -> (1, 16, 88)?\n",
    "        output_seq = torch.abs(output_seq) # !\n",
    "        # print('Output shape C: ',output_seq.shape, output_seq)\n",
    "        output_seq = self.fc(output_seq)\n",
    "        # print('Output shape D: ',output_seq.shape, output_seq)\n",
    "\n",
    "#         for batx in output_seq:\n",
    "#             for frame in batx:\n",
    "#                 frame = self.embedding.weight[ix_to_word[tuple(frame)]]\n",
    "\n",
    "        output_seq = self.sigmoid(output_seq)\n",
    "        # print('Output shape E: ',output_seq.shape, output_seq)\n",
    "\n",
    "        # output_seq = expanded_output_seq.squeeze(-1)\n",
    "\n",
    "        return output_seq, (hidden, cell)\n",
    "\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        # This method generates the first hidden state of zeros which we'll use in the forward pass\n",
    "        # We'll send the tensor holding the hidden state to the device we specified earlier as well\n",
    "        hidden = torch.zeros(self.num_layers*2, batch_size, self.hidden_size).float().to(self.device)\n",
    "        cell = torch.zeros(self.num_layers*2, batch_size, self.hidden_size).float().to(self.device)\n",
    "\n",
    "        return (hidden, cell)\n",
    "\n",
    "\n",
    "\n",
    "    def plot_loss_update(self, i, n, mb, train_loss):\n",
    "        '''\n",
    "            Dynamically print the loss plot during the training/validation loop.\n",
    "            Expects epoch to start from 1.\n",
    "        '''\n",
    "\n",
    "        mb.names = ['Loss']\n",
    "        x = range(1, i+1)\n",
    "        y = train_loss\n",
    "        graphs = [[x,train_loss]]\n",
    "        x_margin = 0.2\n",
    "        y_margin = 0.05\n",
    "        x_bounds = [1-x_margin, n+x_margin]\n",
    "        y_bounds = [np.min(y)-y_margin, np.max(y)+y_margin]\n",
    "\n",
    "        mb.update_graph(graphs, x_bounds, y_bounds)\n",
    "\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def generate(self, context, resolution, predict_amount=1, temperature=0.5, batch_size=1):\n",
    "        '''\n",
    "            Context: MHE matrix with dims (BEAT_AMOUNT, KEYBOARD_SIZE)\n",
    "        '''\n",
    "\n",
    "        hidden, cell = self.init_hidden(batch_size)\n",
    "\n",
    "        # Send context data to GPU and cast to float\n",
    "        if isinstance(context, torch.Tensor):\n",
    "          context = context.to(self.device)\n",
    "          context = context.float()\n",
    "        else:\n",
    "          context = torch.from_numpy(context.astype(float)).float().to(self.device)\n",
    "\n",
    "        # Amount of beats in the context\n",
    "        context_beat_amount = len(context) - resolution\n",
    "\n",
    "        # Feed context to model\n",
    "        for i in range(context_beat_amount):\n",
    "            # Get frames for iteration beat\n",
    "            context_beat_i = context[i:i + resolution]\n",
    "\n",
    "            # We DONT CARE about the output here.\n",
    "            # We are just feeding the model with the\n",
    "            # context we received as input\n",
    "            _, (hidden, cell) = self.mmodel(context_beat_i,\n",
    "                                      (hidden, cell))\n",
    "\n",
    "        # We CARE about the output from the last context beat\n",
    "        previous_beat = context[context_beat_amount:]\n",
    "\n",
    "        output_beats = []\n",
    "        for _ in range(predict_amount):\n",
    "            '''\n",
    "            Here, output_seq has it's first\n",
    "            (resolution-1) frames equal to the previous\n",
    "            beat and the last one different,\n",
    "            the generated frame.\n",
    "\n",
    "            So now we will repeat this line of code\n",
    "            until all its frames are new.\n",
    "            '''\n",
    "            output_seq, (hidden, cell) = self(previous_beat, hidden, cell)\n",
    "\n",
    "            # Compute the other remaining frames\n",
    "            for _ in range(resolution - 1):\n",
    "                '''\n",
    "                As the returned tensor holds Float64s (probabilities)\n",
    "                and the input type of the model is a boolean int (0 or 1).\n",
    "                So we call the torch.where func to make valeus greater\n",
    "                or equal to (1-temperature) become 1 and 0 otherwise.\n",
    "                '''\n",
    "                output_seq = torch.where(output_seq >= (1-temperature), 1, 0).float()\n",
    "                output_seq, (hidden, cell) = self.model(output_seq, hidden, cell)\n",
    "\n",
    "                # update\n",
    "                previous_beat = output_seq\n",
    "\n",
    "\n",
    "            # Make 1s and 0s become booleans\n",
    "            output_seq = np.where(output_seq.cpu() >= (1-temperature), True, False)\n",
    "            output_beats.append(output_seq)\n",
    "\n",
    "        # print(out, out.shape)\n",
    "        return np.array(output_beats, dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a4ee697",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}