{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "beginning-framing",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "# Papagaio - MIDI generation using Bi-Directional LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "female-trash",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "## Setup\n",
    "\n",
    "##### Install, import and configure dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complicated-occurrence",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": true,
     "source_hidden": false
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "!pip install -q music21\n",
    "!pip install -q fastprogress\n",
    "# !pip install -q midi2audio\n",
    "# !pip install -q fluidsynth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powerful-baseline",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "source_hidden": false
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Basic libraries\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import pickle\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Preprocessing data libraries\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "# Model libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Data visualization\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Utils\n",
    "import music21\n",
    "from fastprogress.fastprogress import master_bar, progress_bar\n",
    "\n",
    "# Playing files\n",
    "# from midi2audio import FluidSynth\n",
    "\n",
    "\n",
    "# Codification modules\n",
    "from MidiExpress import read, write\n",
    "\n",
    "# Environment setup\n",
    "%matplotlib inline\n",
    "# music21.configure.run()\n",
    "import notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "built-pennsylvania",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "##### Set device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structural-cigarette",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "source_hidden": false
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optimum-extreme",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "# DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promising-trading",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "##### Separate Stackframe data from Info data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "persistent-stationery",
   "metadata": {
    "gradient": {
     "editing": false,
     "source_hidden": false
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# TODO: receive a input int for the amount of info data (currently 4).\n",
    "#       this way testing will be easier.\n",
    "\n",
    "def getPerformance(data, first_frame, last_frame, to_float=True):\n",
    "    stackframe = data.iloc[first_frame:last_frame, 4:]\n",
    "    stackframe = stackframe.to_numpy()\n",
    "\n",
    "    if to_float:\n",
    "        stackframe.astype(float)\n",
    "        stackframe = stackframe + 0.0\n",
    "\n",
    "    return stackframe\n",
    "\n",
    "def getInfo(data, first_frame, last_frame):\n",
    "    infos = data.iloc[first_frame:last_frame, 0:4]\n",
    "    return infos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6472e50f-4ced-4d1a-b62b-b1d93b09b317",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "##### Merge Stackframe and Info to match the codification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bf69f8-4df1-4b40-a214-8f656cf2aaf5",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def mergeData(infos, stackframe, instrument, midi_offset):\n",
    "\n",
    "    # (A, B, C)\n",
    "    #\n",
    "    # A -> number of measures (bars)\n",
    "    # B -> number of frames (resolution)\n",
    "    # C -> number of notes (keyboard size)\n",
    "\n",
    "    n_measures = stackframe.shape[0]\n",
    "    resolution = stackframe.shape[1]\n",
    "    keyboard_size = stackframe.shape[2]\n",
    "\n",
    "    # Generate note names and use as column\n",
    "    sf_columns = [key_index2note(i, midi_offset).nameWithOctave for i in range(keyboard_size)]\n",
    "    \n",
    "    # Initialize blank df with notes column\n",
    "    measures = pd.DataFrame([], columns=sf_columns)\n",
    "    measures.index.name = 'inst'\n",
    "    \n",
    "    # \n",
    "    for i in range(n_measures):\n",
    "        indexes = pd.Series([instrument for i in range(resolution)])\n",
    "        decoded_measure = pd.DataFrame(stackframe[i], columns=sf_columns).set_index(pd.Index(indexes)) \n",
    "        measures = measures.append(decoded_measure) \n",
    "\n",
    "    print(f'Info shape {infos.shape} | measures shape {measures.shape}')\n",
    "    \n",
    "    output = pd.concat([infos, measures], axis=1)\n",
    "\n",
    "    print(f'Result shape {output.shape}')\n",
    "\n",
    "    return output\n",
    "\n",
    "# Reshape so that we have all frames in one dimension\n",
    "# generated_sf = generated_sf.reshape(-1, generated_sf.shape[-1])\n",
    "# print(f'Reshaped stackframe: \\n {generated_sf} \\t Shape: {generated_sf.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unexpected-compensation",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "##### Read all dataset and isolates the data from a single instrument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mature-parker",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "source_hidden": false
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def createInstrumentPerformanceDataset(datasetPath, instrument, resolution):\n",
    "    instrumentPerformanceDataset = []\n",
    "    interpreted_files = glob.glob(f'{datasetPath}**/**.pkl', recursive=True)\n",
    "    for int_file in interpreted_files:\n",
    "\n",
    "        int_file_path = Path(int_file)\n",
    "        interpreted_file = pd.read_pickle(int_file_path)\n",
    "        # print(interpreted_file.head())\n",
    "\n",
    "        interpreted_instrument = interpreted_file[interpreted_file.index==instrument]\n",
    "        if(interpreted_instrument.empty):\n",
    "            continue\n",
    "        # print(interpreted_instrument.head())\n",
    "\n",
    "        first_frame = 0\n",
    "        last_frame = len(interpreted_instrument)\n",
    "\n",
    "        interpreted_performance = getStackframe(interpreted_instrument, first_frame=first_frame, last_frame=last_frame)\n",
    "        # print(interpreted_performance.head())\n",
    "        \n",
    "        instrumentPerformanceDataset.append(np.array(interpreted_performance))\n",
    "      \n",
    "    return instrumentPerformanceDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranging-poverty",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "##### Split dataset into two blocks, one frame apart at every single index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "antique-roulette",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "source_hidden": false
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def preparePerformanceTrainingExamples(dataset, resolution):\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    # create two arrays X, y with bars\n",
    "    for performance in dataset:\n",
    "        # create the frame blocks shifted in one position\n",
    "        for i in range(performance.shape[0] - resolution):\n",
    "            j = i + resolution\n",
    "            xa = performance[i:j]\n",
    "            ya = performance[i+1:j+1]\n",
    "            X.append(xa)\n",
    "            y.append(ya)\n",
    "        \n",
    "    X = np.array(X, dtype='float64')\n",
    "    y = np.array(y, dtype='float64')\n",
    "    X = torch.from_numpy(X)\n",
    "    y = torch.from_numpy(y)\n",
    "    \n",
    "    training_ds = TensorDataset(X, y) # (X, y)\n",
    "    return training_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec2a182-c939-4475-84a2-265b5cab65e9",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def getPerformanceSample(dataloader):\n",
    "\n",
    "  n_training_examples = len(dataloader.dataset.tensors[0])\n",
    "\n",
    "  input = torch.zeros(n_training_examples, SETTINGS.RESOLUTION, SETTINGS.KEYBOARD_SIZE)\n",
    "  target = torch.zeros(n_training_examples, SETTINGS.RESOLUTION, SETTINGS.KEYBOARD_SIZE)\n",
    "\n",
    "  for sample, (xb, yb) in enumerate(dataloader): # gets the samples\n",
    "    input[sample] = xb\n",
    "    target[sample] = yb\n",
    "  \n",
    "  return input, target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "violent-baker",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optical-marriage",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "##### Define model class with heritage of PyTorch's Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "academic-brisbane",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "source_hidden": false
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class BI_LSTM(nn.Module):\n",
    "  def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "    super(BI_LSTM, self).__init__()\n",
    "\n",
    "    self.hidden_size = hidden_size\n",
    "    self.num_layers = num_layers\n",
    "    self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=False, bidirectional=True)\n",
    "    self.fc1 = nn.Linear(hidden_size*2, hidden_size*2)\n",
    "    self.fc2 = nn.Linear(hidden_size*2, output_size)\n",
    "    self.relu = nn.ReLU()\n",
    "    self.softplus = nn.Softplus(beta=500, threshold=0)\n",
    "    self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    # self.fromInstrument = \n",
    "    # self.toInstrument = \n",
    "\n",
    "  def forward(self, x, hidden, cell):\n",
    "    # Passing in the input and hidden state into the model and obtaining outputs\n",
    "    out, (hidden, cell) = self.lstm(x.unsqueeze(1), (hidden, cell))\n",
    "\n",
    "    # Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "    out = out.contiguous().view(-1, self.hidden_size*2)\n",
    "\n",
    "    out = self.fc2(out)\n",
    "    out = self.sigmoid(out)\n",
    "    \n",
    "    return out, (hidden, cell)\n",
    "\n",
    "  def init_hidden(self, batch_size):\n",
    "    # This method generates the first hidden state of zeros which we'll use in the forward pass\n",
    "    # We'll send the tensor holding the hidden state to the device we specified earlier as well\n",
    "    hidden = torch.zeros(self.num_layers*2, batch_size, self.hidden_size).to(device)\n",
    "    cell = torch.zeros(self.num_layers*2, batch_size, self.hidden_size).to(device)\n",
    "    \n",
    "    return hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composed-measurement",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": true,
     "source_hidden": false
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def plot_loss_update(epoch, epochs, mb, train_loss):\n",
    "    \"\"\" dynamically print the loss plot during the training/validation loop.\n",
    "        expects epoch to start from 1.\n",
    "    \"\"\"\n",
    "    x = range(1, epoch+1)\n",
    "    y = train_loss\n",
    "    graphs = [[x,train_loss]]\n",
    "    x_margin = 0.2\n",
    "    y_margin = 0.05\n",
    "    x_bounds = [1-x_margin, epochs+x_margin]\n",
    "    y_bounds = [np.min(y)-y_margin, np.max(y)+y_margin]\n",
    "\n",
    "    mb.update_graph(graphs, x_bounds, y_bounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "million-diameter",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "##### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "martial-partition",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "source_hidden": false
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss_fn, dataloader, save_as, batch_size=1, num_epochs=50):\n",
    "    writer = SummaryWriter()\n",
    "\n",
    "    print(\"[Train Starting]\")\n",
    "\n",
    "    s_time = time.time()\n",
    "\n",
    "    mb = master_bar(range(1, num_epochs+1))\n",
    "    mb.names = ['Loss', 'FrameBlock']\n",
    "    train_loss = []\n",
    "\n",
    "\n",
    "    for epoch_index in mb:\n",
    "        count = 0\n",
    "        training_loss = 0.0\n",
    "\n",
    "        n_training_examples = len(dataloader.dataset.tensors[0])\n",
    "\n",
    "        input, target = getPerformanceSample(dataloader)\n",
    "        input = input.to(device)\n",
    "        target = target.to(device)\n",
    "        \n",
    "        # Initialize hidden and cells\n",
    "        hidden, cell = model.init_hidden(batch_size)\n",
    "\n",
    "        for training_example_index in progress_bar(range(n_training_examples), parent=mb):\n",
    "\n",
    "            # Generate predictions\n",
    "            frameblock = input[training_example_index,:]\n",
    "            output, (hidden, cell) = model(frameblock, hidden, cell)\n",
    "            \n",
    "\n",
    "            # Compute the loss and backpropag\n",
    "            loss_step = loss_fn(output, target[training_example_index, :])\n",
    "\n",
    "            hidden = hidden.detach()\n",
    "            cell = cell.detach()\n",
    "\n",
    "            count += 1\n",
    "\n",
    "            loss_step.backward() # Does backpropagation and calculates gradients\n",
    "            optimizer.step() # Updates the weights accordingly\n",
    "            optimizer.zero_grad() # Clears existing gradients from previous frame\n",
    "\n",
    "            training_loss += loss_step.item()\n",
    "\n",
    "            mb.child.comment = f'[Loss {training_loss:.8f}]'\n",
    "\n",
    "        training_loss /= len(dataloader.dataset)\n",
    "        writer.add_scalar(\"Loss/train\", training_loss, epoch_index)\n",
    "\n",
    "        train_loss.append(training_loss)\n",
    "        mb.main_bar.comment = f'[Epoch {epoch_index} | Loss {training_loss:.8f}]'\n",
    "        plot_loss_update(epoch_index, num_epochs, mb, train_loss)\n",
    "\n",
    "        if (epoch_index % 5) == 0:\n",
    "            torch.save(model, f'{save_as}[{epoch_index}].pt')\n",
    "\n",
    "    writer.flush()\n",
    "    writer.close()\n",
    "\n",
    "    print(f'[Finished training with Loss {training_loss:.8f} (took {time.time() - s_time} seconds)]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floating-spine",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "##### Given the model and some context data, generate a certain amount of measures (default: 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "realistic-overhead",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "source_hidden": false
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Be able to especify the number of measures to predict!\n",
    "\n",
    "@torch.no_grad()\n",
    "def generateMeasures(model, context, resolution, amount=1, temperature=0.5, batch_size=1):\n",
    "    hidden, cell = model.init_hidden(batch_size)\n",
    "\n",
    "    if isinstance(context, torch.Tensor):\n",
    "      # send to gpu\n",
    "      context_performance_block = context.cuda()\n",
    "      # cast to float\n",
    "      context_performance_block = context_performance_block.float()\n",
    "    else:\n",
    "      context_performance_block = torch.from_numpy(context.astype(float)).float().to(device)\n",
    "\n",
    "    # amount of frameblocks in the context input\n",
    "    n_context_performance_block = len(context_performance_block) - resolution\n",
    "\n",
    "    # getting context iterating over\n",
    "    # N-1 of the frameblocks\n",
    "\n",
    "    for i in range(n_context_performance_block):\n",
    "        context_performance = context_performance_block[i:i + resolution]\n",
    "\n",
    "        # we dont care about the output here.\n",
    "        # we are just feeding the model with the\n",
    "        # context we received as input\n",
    "        _, (hidden, cell) = model(context_performance,\n",
    "                                  hidden, cell)\n",
    "\n",
    "    # we must get the output from the last context fb\n",
    "    last_context_performance = context_performance_block[context_performance:]\n",
    "\n",
    "    output_measures = []\n",
    "    for _ in range(amount):\n",
    "      \n",
    "      out, (hidden, cell) = model(last_context_performance, hidden, cell)\n",
    "      \n",
    "      # generate the other remaining frames\n",
    "      for i in range(resolution- 1):\n",
    "        out = torch.where(out >= (1-temperature), 1, 0).float()\n",
    "        out, (hidden, cell) = model(out, hidden, cell)\n",
    "\n",
    "        # update last frame block\n",
    "        last_context_performance = out\n",
    "\n",
    "\n",
    "      out = np.where(out.cpu() >= (1-temperature), True, False)\n",
    "      output_measures.append(out)\n",
    "\n",
    "    # print(out, out.shape)\n",
    "    return np.array(output_measures, dtype=bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "administrative-proposition",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "##### Instanciate with desired parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worldwide-fifty",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "source_hidden": false
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "SETTINGS = pd.Series(\n",
    "  {\n",
    "    'RESOLUTION': 36, # Frame per measure amount\n",
    "    'KEYBOARD_SIZE': 88, # Amount of keys in the Model's Keyboard\n",
    "    'KEYBOARD_OFFSET': 20 # MIDI index for the first Model's Keyboard key\n",
    "  }\n",
    ")\n",
    "\n",
    "\n",
    "NUM_LAYERS = 4\n",
    "\n",
    "# Instantiate the model with hyperparameters\n",
    "# We'll also set the model to the device that we defined earlier\n",
    "model = BI_LSTM(input_size=SETTINGS.KEYBOARD_SIZE,\n",
    "                output_size=SETTINGS.KEYBOARD_SIZE,\n",
    "                hidden_size=SETTINGS.RESOLUTION,\n",
    "                num_layers=NUM_LAYERS).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extra-satellite",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "# TRAIN MODEL\n",
    "\n",
    "##### Set training options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opponent-calculator",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "source_hidden": false
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "lr = 3e-4 # Learning Rate\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "loss_fn = nn.BCELoss() # Binary Cross Entropy\n",
    "\n",
    "MODELS_PATH = '../models/'\n",
    "MODEL_NAME = 'BI_LSTM'\n",
    "\n",
    "N_EPOCHS = 50 # Number of times that the model will go trough all the "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398f4739-7e80-4205-ab32-de11091984f8",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "##### Let's create a dataset for a given instrument, in this case I'll choose piano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e68fc89-68f2-4f16-8a80-2d2fe343f5af",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "source_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset original, Instrument Electric guitar, Instrument Performance Dataset size 75\n"
     ]
    }
   ],
   "source": [
    "datasetName = 'original'\n",
    "datasetPath = f'../datasets/interpretation/{datasetName}/'\n",
    "\n",
    "modelType = 'prediction'\n",
    "modelPath  = f'../models/{modelType}/{datasetName}/'\n",
    "os.makedirs(modelPath, exist_ok=True)\n",
    "\n",
    "INSTRUMENT = 'Electric guitar'\n",
    "\n",
    "instrumentPerformanceDataset = createInstrumentPerformanceDataset(datasetPath, INSTRUMENT, SETTINGS.RESOLUTION)\n",
    "print(f'Dataset {datasetName}, Instrument {INSTRUMENT}, Instrument Performance Dataset size {len(instrumentPerformanceDataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9047906-e015-46e6-9227-d428f43b8bc2",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "##### Prepare training Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b3d8e0-becc-4915-bfc1-5282832cf5e6",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "source_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of training examples:\t161170\n"
     ]
    }
   ],
   "source": [
    "training_ds = preparePerformanceTrainingExamples(instrumentPerformanceDataset, SETTINGS.RESOLUTION)\n",
    "training_dl = DataLoader(training_ds, batch_size=1, shuffle=False)\n",
    "\n",
    "print(f'Amount of training examples:\\t{len(training_dl.dataset.tensors[0])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "future-hardware",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "### Run train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bright-setting",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "source_hidden": false
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train Starting]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='9' class='' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      18.00% [9/50 5:22:23<24:28:42 [Epoch 9 | Loss 0.00171608]]\n",
       "    </div>\n",
       "    \n",
       "\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='139623' class='' max='161170' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      86.63% [139623/161170 30:54<04:46 [Loss 232.90554076]]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "display_id": "ac9fb00255175a589ac15ff31a1c085b"
     },
     "output_type": "display_data",
     "transient": {
      "display_id": "ac9fb00255175a589ac15ff31a1c085b"
     }
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "display_id": "1812af948e64891ee73706ae3799665d",
      "image/png": {
       "height": 252,
       "width": 380
      }
     },
     "output_type": "display_data",
     "transient": {
      "display_id": "1812af948e64891ee73706ae3799665d"
     }
    }
   ],
   "source": [
    "SAVE_AS = f'{modelPath}{MODEL_NAME}_[{INSTRUMENT}]' # Name of the output LSTM data\n",
    "\n",
    "#!jupyter nbextension enable --py widgetsnbextension\n",
    "train(model, optimizer, loss_fn, training_dl, SAVE_AS, num_epochs=N_EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba92780e-8424-4a49-a099-060209cbc2de",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "# GENERATE\n",
    "##### Prepare context data representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8696fa0-b349-474d-913d-e5e60ae067e5",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "source_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'INSTRUMENT' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-a4e3efa893b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Filter by instrument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mCONTEXT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCONTEXT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONTEXT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mINSTRUMENT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# If the file does not contain the instrument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'INSTRUMENT' is not defined"
     ]
    }
   ],
   "source": [
    "# Read context file\n",
    "CONTEXT = pd.read_pickle(datasetPath + 'Foo Fighters/The Pretender.pkl')\n",
    "\n",
    "# Filter by instrument\n",
    "CONTEXT = CONTEXT[CONTEXT.index==INSTRUMENT]\n",
    "\n",
    "# If the file does not contain the instrument\n",
    "if len(CONTEXT) == 0:\n",
    "    raise ValueError(f'Oops, it seems that the selected context file does not contain this instrument ({INSTRUMENT}).')\n",
    "\n",
    "print(f'{INSTRUMENT} context data shape {CONTEXT.shape}')\n",
    "print(f'{INSTRUMENT} context measures {int(CONTEXT.shape[0] / RESOLUTION)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9650113-8117-46fd-91e9-6a97c8bfb2ef",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "##### Set generation parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430a53f3-3f88-4bad-9ca2-e267a0867585",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": true,
     "source_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-19-946ff3a5112a>, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-19-946ff3a5112a>\"\u001b[0;36m, line \u001b[0;32m12\u001b[0m\n\u001b[0;31m    last_generated_frame = first_generated_frame + SETTINGS..RESOLUTION*GENERATE_AMOUNT\u001b[0m\n\u001b[0m                                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "CONTEXT_FIRST_MEASURE = 1\n",
    "CONTEXT_AMOUNT = 50 # Amount of measures of context\n",
    "GENERATE_AMOUNT = 50 # Amount of measures to generate\n",
    "TEMPERATURE = 0.5 # Predicted probability must be >= 80% to note be played\n",
    "\n",
    "# INFO_SIZE = 4\n",
    "\n",
    "first_context_frame = (CONTEXT_FIRST_MEASURE-1)*SETTINGS.RESOLUTION\n",
    "last_context_frame = first_context_frame + SETTINGS.RESOLUTION*CONTEXT_AMOUNT\n",
    "\n",
    "first_generated_frame = last_context_frame\n",
    "last_generated_frame = first_generated_frame + SETTINGS.RESOLUTION*GENERATE_AMOUNT\n",
    "\n",
    "context_info = getInfo(CONTEXT, first_context_frame, last_context_frame)\n",
    "context_performance = getPerformance(CONTEXT, first_context_frame, last_context_frame, to_float=True)\n",
    "\n",
    "generated_info = getInfo(CONTEXT, first_generated_frame, last_generated_frame)\n",
    "\n",
    "print(f'CONTEXT_INFO: \\n {context_info} \\n\\n')\n",
    "print(f'CONTEXT_SF: \\n {context_sf} \\t Shape: {context_sf.shape}')\n",
    "\n",
    "print(f'GENERATED_INFO: \\n {generated_info}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2e669e-d63d-495b-8a9c-63030bd9b8e2",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "##### Let's see the context we'll feed the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fac38c-75ac-4cdf-b62f-95e333af3346",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "source_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'RESOLUTION'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-f52ad45c2c18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCONTEXT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSETTINGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRESOLUTION\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/notebooks/src/MidiExpress/write.py\u001b[0m in \u001b[0;36mfile\u001b[0;34m(interpretation, SETTINGS, save_as)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mtimer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         part = instrument(SETTINGS,\n\u001b[0m\u001b[1;32m    272\u001b[0m                           \u001b[0mINSTRUMENT_BLOCK\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m                           \u001b[0mENVIRONMENT_BLOCK\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebooks/src/MidiExpress/write.py\u001b[0m in \u001b[0;36minstrument\u001b[0;34m(SETTINGS, INSTRUMENT_BLOCK, ENVIRONMENT_BLOCK, PERFORMANCE_BLOCK, save_as)\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;31m# total number of measures (bars)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# in this part\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m     \u001b[0mn_measures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPERFORMANCE_BLOCK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mSETTINGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRESOLUTION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# decode measures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5138\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5139\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'RESOLUTION'"
     ]
    }
   ],
   "source": [
    "write.file(CONTEXT, SETTINGS.RESOLUTION).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fb98e3-5fe3-4695-8554-aabcab0c9a3b",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "##### Generate measures stackframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf32858-c257-477d-b9b7-947f0948230b",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "source_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'context_performance' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-9f75785488fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstart_timer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m generated_performance = generateMeasures(   model,\n\u001b[0;32m----> 3\u001b[0;31m                                             \u001b[0mcontext_performance\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m                                             \u001b[0mSETTINGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRESOLUTION\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                             \u001b[0mamount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mGENERATE_AMOUNT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'context_performance' is not defined"
     ]
    }
   ],
   "source": [
    "start_timer = time.time()\n",
    "generated_performance = generateMeasures(   model,\n",
    "                                            context_performance,\n",
    "                                            SETTINGS.RESOLUTION,\n",
    "                                            amount=GENERATE_AMOUNT,\n",
    "                                            temperature=TEMPERATURE\n",
    "                                            )\n",
    "end_timer = time.time()\n",
    "print(f'GENERATED PERFORMANCE: \\n {generated_performance} \\t Shape: {generated_performance.shape}')\n",
    "print(f'Generated {generated_performance.shape[0]} measures in {end_timer - start_timer} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908db96d-d520-4a10-aa07-01aa0ecf56ec",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "##### Merge Info and StackFrame to get the complete, decodable representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38c66bb-82f9-4fd6-9465-eea041c59aa1",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "source_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generated_info' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-ad899c950abf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Merge StackFrame and Info blocks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgenerated_representation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmergeData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerated_performance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mINSTRUMENT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSETTINGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMIDI_OFFSET\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Generated representation: \\n {generated_representation.to_string()}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'generated_info' is not defined"
     ]
    }
   ],
   "source": [
    "# Merge StackFrame and Info blocks\n",
    "generated_representation = mergeData(generated_info, generated_performance, INSTRUMENT, SETTINGS.MIDI_OFFSET)\n",
    "\n",
    "print(f'Generated representation: \\n {generated_representation.to_string()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30847d4b-2296-4137-b244-29adb897c6b3",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "##### Send generated representation to the decoder module and plot result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c319cc-5829-49e0-9680-6ddbf9880bf5",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": true,
     "source_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generated_representation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-5e7ee4fd85eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Send representation to decoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mgenerated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_representation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSETTINGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRESOLUTION\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_as\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mOUTPUT_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mgenerated\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'generated_representation' is not defined"
     ]
    }
   ],
   "source": [
    "OUTPUT_PATH = f'../results/{datasetName}'\n",
    "\n",
    "# Send representation to decoder\n",
    "generated = write.file(generated_representation, SETTINGS.RESOLUTION, save_as=OUTPUT_PATH)\n",
    "\n",
    "generated.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e76143-1250-478c-8afc-21a007c4b2c7",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "# HEARING GENERATED\n",
    "##### Now we can play the generated midi file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96361bc9-9704-4dab-afff-c9f1b5ddd230",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "source_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FluidSynth' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-c446d278ef1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msynth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFluidSynth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msynth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmidi_to_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOUTPUT_PATH\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.mid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOUTPUT_PATH\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.mid'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.wav'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msynth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplay_midi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'FluidSynth' is not defined"
     ]
    }
   ],
   "source": [
    "synth = FluidSynth()\n",
    "synth.midi_to_audio(OUTPUT_PATH+'.mid', OUTPUT_PATH+'.mid'+'.wav')\n",
    "synth.play_midi()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
